{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "f_ai_chall1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xcVxfOqKB0pR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io, transform\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A17uhSPw-Ykm",
        "outputId": "ebb7e422-2fb3-441a-bd77-b0ab359bcceb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = { \n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "IgZ5Y-N2PaYH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/oxford-102-flowers/'"
      ],
      "metadata": {
        "id": "DargyYouS10I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = {}\n",
        "datasets['train'] = []\n",
        "datasets['valid'] = []\n",
        "datasets['test'] = []\n",
        "\n",
        "# classes = []\n",
        "\n",
        "def load_paths(x):\n",
        "  with open(f'{data_dir}/{x}.txt', 'r') as f:\n",
        "    for line in f:\n",
        "      t = line.split()\n",
        "      t[0] = data_dir + t[0]\n",
        "      t[1] = int(t[1])\n",
        "\n",
        "      datasets[x].append(t)\n",
        "\n",
        "load_paths('train')\n",
        "load_paths('valid')\n",
        "load_paths('test')"
      ],
      "metadata": {
        "id": "3nwRncJKUono"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowersDataset(Dataset):\n",
        "\n",
        "  def __init__(self, samples, transform = None):\n",
        "    self.samples = samples\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.samples)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.to_list()\n",
        "\n",
        "    img_name = os.path.join(self.samples[idx][0])\n",
        "    image = io.imread(img_name)\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    label = self.samples[idx][1]\n",
        "\n",
        "    # sample = (image, label)\n",
        "\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "31IlfWDJ_pRM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flower_dataset = {x: FlowersDataset(samples = datasets[x], transform = data_transforms[x]) for x in ['train', 'valid', 'test']}\n",
        "\n",
        "flower_dataloaders = {x: torch.utils.data.DataLoader(flower_dataset[x], batch_size=8, shuffle=True, num_workers=2) for x in ['train', 'valid', 'test']}\n",
        "\n",
        "dataset_sizes = {x: len(flower_dataset[x]) for x in ['train', 'valid', 'test']}\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "ytGliKXxCO4z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, datald=flower_dataloaders):\n",
        "\n",
        "  since = time.time()\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "      print('-' * 10)\n",
        "\n",
        "      # Each epoch has a training and validation phase\n",
        "      for phase in ['train', 'valid']:\n",
        "          if phase == 'train':\n",
        "              model.train()  # Set model to training mode\n",
        "          else:\n",
        "              model.eval()   # Set model to evaluate mode\n",
        "\n",
        "          running_loss = 0.0\n",
        "          running_corrects = 0\n",
        "\n",
        "          # Iterate over data.\n",
        "          for inputs, labels in datald[phase]:\n",
        "\n",
        "              \n",
        "              inputs = inputs.to(device)\n",
        "              \n",
        "              labels = labels.to(device)\n",
        "\n",
        "              # zero the parameter gradients\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # forward\n",
        "              # track history if only in train\n",
        "              with torch.set_grad_enabled(phase == 'train'):\n",
        "                  outputs = model(inputs)\n",
        "                  _, preds = torch.max(outputs, 1)\n",
        "                  loss = criterion(outputs, labels)\n",
        "\n",
        "                  # backward + optimize only if in training phase\n",
        "                  if phase == 'train':\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "\n",
        "              # statistics\n",
        "              running_loss += loss.item() * inputs.size(0)\n",
        "              running_corrects += torch.sum(preds == labels.data)\n",
        "          if phase == 'train':\n",
        "              scheduler.step()\n",
        "\n",
        "          epoch_loss = running_loss / dataset_sizes[phase]\n",
        "          epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "          print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "          # deep copy the model\n",
        "          if phase == 'valid' and epoch_acc > best_acc:\n",
        "              best_acc = epoch_acc\n",
        "              best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "      print()\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "  print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "  # load best model weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model"
      ],
      "metadata": {
        "id": "kQBmvw0JC5sq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, criterion, optimizer, scheduler, num_epochs=25, datald=flower_dataloaders):\n",
        "\n",
        "  since = time.time()\n",
        "  best_acc = 0.0\n",
        "\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "      print('-' * 10)\n",
        "\n",
        "      for phase in ['test']:\n",
        "\n",
        "          model.eval()   # Set model to evaluate mode\n",
        "\n",
        "          running_loss = 0.0\n",
        "          running_corrects = 0\n",
        "\n",
        "          # Iterate over data.\n",
        "          for inputs, labels in datald[phase]:\n",
        "\n",
        "              \n",
        "              inputs = inputs.to(device)\n",
        "              \n",
        "              labels = labels.to(device)\n",
        "\n",
        "              # zero the parameter gradients\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # forward\n",
        "              with torch.set_grad_enabled(False):\n",
        "                  outputs = model(inputs)\n",
        "                  _, preds = torch.max(outputs, 1)\n",
        "                  loss = criterion(outputs, labels)\n",
        "\n",
        "              # statistics\n",
        "              running_loss += loss.item() * inputs.size(0)\n",
        "              running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "          epoch_loss = running_loss / dataset_sizes[phase]\n",
        "          epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "          print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "          # deep copy the model\n",
        "          if epoch_acc > best_acc:\n",
        "              best_acc = epoch_acc\n",
        "              best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "      # print()\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print(f'Testing complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "  print(f'Best test Acc: {best_acc:4f}')"
      ],
      "metadata": {
        "id": "1TeRoZUDy6Bc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n"
      ],
      "metadata": {
        "id": "jJypR5uCstqD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet34(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 102)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "VnHHMknQODuY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEPpS-7AO60w",
        "outputId": "7c28e36f-d7cf-4186-b1da-67ebc2160b82"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 4.4146 Acc: 0.0735\n",
            "valid Loss: 3.1967 Acc: 0.3490\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 3.1139 Acc: 0.3441\n",
            "valid Loss: 1.8870 Acc: 0.6333\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 2.1528 Acc: 0.5892\n",
            "valid Loss: 1.1645 Acc: 0.7422\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 1.4965 Acc: 0.7186\n",
            "valid Loss: 0.8229 Acc: 0.8088\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 1.1702 Acc: 0.7931\n",
            "valid Loss: 0.6527 Acc: 0.8559\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 1.0355 Acc: 0.8176\n",
            "valid Loss: 0.5604 Acc: 0.8627\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.7417 Acc: 0.8784\n",
            "valid Loss: 0.4721 Acc: 0.8922\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.6287 Acc: 0.9010\n",
            "valid Loss: 0.4159 Acc: 0.9088\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.5516 Acc: 0.9137\n",
            "valid Loss: 0.4269 Acc: 0.9029\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.5548 Acc: 0.9118\n",
            "valid Loss: 0.3916 Acc: 0.9059\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.5143 Acc: 0.9294\n",
            "valid Loss: 0.3996 Acc: 0.9078\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.5192 Acc: 0.9196\n",
            "valid Loss: 0.3873 Acc: 0.9098\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.4907 Acc: 0.9343\n",
            "valid Loss: 0.3901 Acc: 0.9098\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.5095 Acc: 0.9216\n",
            "valid Loss: 0.3773 Acc: 0.9069\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.4927 Acc: 0.9343\n",
            "valid Loss: 0.3713 Acc: 0.9078\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.4871 Acc: 0.9225\n",
            "valid Loss: 0.3721 Acc: 0.9108\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.5055 Acc: 0.9206\n",
            "valid Loss: 0.3980 Acc: 0.9049\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.4999 Acc: 0.9304\n",
            "valid Loss: 0.3658 Acc: 0.9147\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.4686 Acc: 0.9412\n",
            "valid Loss: 0.3894 Acc: 0.9029\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.5210 Acc: 0.9255\n",
            "valid Loss: 0.3565 Acc: 0.9206\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.4655 Acc: 0.9333\n",
            "valid Loss: 0.3705 Acc: 0.9098\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.4556 Acc: 0.9353\n",
            "valid Loss: 0.3793 Acc: 0.9059\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.4647 Acc: 0.9324\n",
            "valid Loss: 0.3836 Acc: 0.9078\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.4245 Acc: 0.9441\n",
            "valid Loss: 0.3938 Acc: 0.9049\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.4520 Acc: 0.9480\n",
            "valid Loss: 0.3668 Acc: 0.9157\n",
            "\n",
            "Training complete in 9m 23s\n",
            "Best val Acc: 0.920588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsrv5rF40Hir",
        "outputId": "d6e884b8-0854-4590-e46c-439fafec58bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/0\n",
            "----------\n",
            "test Loss: 0.4654 Acc: 0.8888\n",
            "\n",
            "Testing complete in 1m 5s\n",
            "Best test Acc: 0.888762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = models.resnet34(pretrained=True)\n",
        "num_ftrs = model_2.fc.in_features\n",
        "# Here the size of each output sample is set to 102.\n",
        "model_2.fc = nn.Linear(num_ftrs, 102)\n",
        "\n",
        "model_2 = model_2.to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_2 = optim.SGD(model_2.parameters(), lr=0.005, momentum=0.9)"
      ],
      "metadata": {
        "id": "Bvvz6BiRicye"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = train_model(model_2, criterion, optimizer_2, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijgPcLAtipIv",
        "outputId": "5d93e236-71f2-4d59-f4e7-f9874c92c880"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 4.3731 Acc: 0.0980\n",
            "valid Loss: 3.2552 Acc: 0.2990\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 2.8429 Acc: 0.3275\n",
            "valid Loss: 2.2123 Acc: 0.4667\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 2.2032 Acc: 0.4353\n",
            "valid Loss: 1.7138 Acc: 0.5824\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 1.8529 Acc: 0.5186\n",
            "valid Loss: 1.7604 Acc: 0.5804\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 1.5560 Acc: 0.5833\n",
            "valid Loss: 1.8471 Acc: 0.6108\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 1.3870 Acc: 0.6157\n",
            "valid Loss: 1.1393 Acc: 0.7333\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 1.1774 Acc: 0.6637\n",
            "valid Loss: 1.4956 Acc: 0.6882\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 1.1122 Acc: 0.6941\n",
            "valid Loss: 1.3608 Acc: 0.7039\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.9707 Acc: 0.7441\n",
            "valid Loss: 1.0811 Acc: 0.7667\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.8907 Acc: 0.7539\n",
            "valid Loss: 0.9573 Acc: 0.7794\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.7946 Acc: 0.7990\n",
            "valid Loss: 1.0274 Acc: 0.7745\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.8634 Acc: 0.7676\n",
            "valid Loss: 1.2219 Acc: 0.7422\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.8618 Acc: 0.7725\n",
            "valid Loss: 0.9629 Acc: 0.7725\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.8109 Acc: 0.7765\n",
            "valid Loss: 1.0059 Acc: 0.7549\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.7077 Acc: 0.8176\n",
            "valid Loss: 0.8188 Acc: 0.8196\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.5858 Acc: 0.8392\n",
            "valid Loss: 0.9239 Acc: 0.7882\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.6242 Acc: 0.8294\n",
            "valid Loss: 0.9283 Acc: 0.7882\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.6818 Acc: 0.8167\n",
            "valid Loss: 0.8789 Acc: 0.8088\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.6035 Acc: 0.8480\n",
            "valid Loss: 0.7962 Acc: 0.8245\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.6187 Acc: 0.8392\n",
            "valid Loss: 0.8011 Acc: 0.8127\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.5316 Acc: 0.8608\n",
            "valid Loss: 0.7434 Acc: 0.8314\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.4286 Acc: 0.8725\n",
            "valid Loss: 0.7180 Acc: 0.8412\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.4318 Acc: 0.8882\n",
            "valid Loss: 0.8131 Acc: 0.8225\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.5144 Acc: 0.8676\n",
            "valid Loss: 0.7458 Acc: 0.8402\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.5297 Acc: 0.8627\n",
            "valid Loss: 0.9276 Acc: 0.7990\n",
            "\n",
            "Training complete in 9m 20s\n",
            "Best val Acc: 0.841176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model_2, criterion, optimizer_2, exp_lr_scheduler, num_epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebV-mk5dC23e",
        "outputId": "4a5c7c7f-a088-481d-d6b0-9028ead6815e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/0\n",
            "----------\n",
            "test Loss: 0.8720 Acc: 0.8099\n",
            "\n",
            "Testing complete in 1m 4s\n",
            "Best test Acc: 0.809888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformations used:**\n",
        "\n",
        "*    RandomResizedCrop(224)\n",
        "*    RandomHorizontalFlip()\n",
        "\n",
        "**Val Accuracy:**\n",
        "\n",
        "* lr = 0.01 -> Accuracy = 0.92\n",
        "* lr = 0.05 -> Accuracy = 0.84\n",
        "\n",
        "**Test Accuracy:**\n",
        "\n",
        "* lr = 0.01 -> Accuracy = 0.88\n",
        "* lr = 0.05 -> Accuracy = 0.80\n"
      ],
      "metadata": {
        "id": "bMAg4nhJI0mo"
      }
    }
  ]
}